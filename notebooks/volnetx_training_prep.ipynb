{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68767246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from volsense_core.data.feature_engineering import build_features\n",
    "from volsense_core.data.fetch import build_dataset\n",
    "from volsense_core.evaluation.feature_selection import (compute_feature_correlations, compute_mutual_information, \n",
    "perform_recursive_feature_elimination, plot_feature_heatmap, rank_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0d5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üåç Fetching market data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.50ticker/s]\n"
     ]
    }
   ],
   "source": [
    "df = build_dataset(tickers=[\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\"], start=\"2005-01-01\", end=\"2025-11-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ebc568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>realized_vol_log</th>\n",
       "      <th>realized_vol</th>\n",
       "      <th>ticker</th>\n",
       "      <th>return</th>\n",
       "      <th>vol_vol</th>\n",
       "      <th>return_sharpe_20d</th>\n",
       "      <th>macd_diff</th>\n",
       "      <th>vol_3d</th>\n",
       "      <th>market_stress_1d_lag</th>\n",
       "      <th>...</th>\n",
       "      <th>vol_60d</th>\n",
       "      <th>vol_entropy</th>\n",
       "      <th>skew_5d</th>\n",
       "      <th>vol_kurt_20d</th>\n",
       "      <th>vol_ratio</th>\n",
       "      <th>ewma_vol_10d</th>\n",
       "      <th>vol_stress</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>vol_skew_20d</th>\n",
       "      <th>abs_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-25</td>\n",
       "      <td>-0.706510</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-26</td>\n",
       "      <td>-0.705208</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.493684</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493479</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>-0.704852</td>\n",
       "      <td>0.494181</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493607</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-28</td>\n",
       "      <td>-0.704045</td>\n",
       "      <td>0.494579</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>0.494255</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.049140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000450</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>-0.837282</td>\n",
       "      <td>0.432884</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.473882</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983558</td>\n",
       "      <td>0.482711</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20903</th>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>-2.020124</td>\n",
       "      <td>0.132638</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.185402</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.142235</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167869</td>\n",
       "      <td>-1315.194138</td>\n",
       "      <td>0.848502</td>\n",
       "      <td>1.632760</td>\n",
       "      <td>0.950492</td>\n",
       "      <td>0.147616</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>60.651309</td>\n",
       "      <td>-0.860415</td>\n",
       "      <td>0.015107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20904</th>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>-1.909825</td>\n",
       "      <td>0.148105</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.237702</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.142801</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166809</td>\n",
       "      <td>-1320.893085</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>1.735806</td>\n",
       "      <td>0.959574</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>58.571901</td>\n",
       "      <td>-0.889229</td>\n",
       "      <td>0.019849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20905</th>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>-1.905825</td>\n",
       "      <td>0.148699</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.214903</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.143147</td>\n",
       "      <td>0.011097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>-1339.605424</td>\n",
       "      <td>0.290157</td>\n",
       "      <td>1.902887</td>\n",
       "      <td>0.966849</td>\n",
       "      <td>0.147886</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>51.533138</td>\n",
       "      <td>-0.936720</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20906</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>-1.632705</td>\n",
       "      <td>0.195399</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.029157</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>0.164068</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164996</td>\n",
       "      <td>-600.297462</td>\n",
       "      <td>-0.895050</td>\n",
       "      <td>7.665364</td>\n",
       "      <td>1.078512</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>47.234082</td>\n",
       "      <td>2.032174</td>\n",
       "      <td>0.029157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20907</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>-1.698286</td>\n",
       "      <td>0.182996</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.015121</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>0.175698</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>-589.253296</td>\n",
       "      <td>-0.213075</td>\n",
       "      <td>4.396396</td>\n",
       "      <td>1.131444</td>\n",
       "      <td>0.161337</td>\n",
       "      <td>0.058284</td>\n",
       "      <td>40.989821</td>\n",
       "      <td>1.775281</td>\n",
       "      <td>0.015121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20908 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  realized_vol_log  realized_vol ticker    return   vol_vol  \\\n",
       "0      2005-01-25         -0.706510      0.493362   AAPL  0.018231  0.000000   \n",
       "1      2005-01-26         -0.705208      0.494005   AAPL  0.002776  0.000455   \n",
       "2      2005-01-27         -0.704852      0.494181   AAPL  0.005398  0.000431   \n",
       "3      2005-01-28         -0.704045      0.494579   AAPL  0.018447  0.000507   \n",
       "4      2005-01-31         -0.837282      0.432884   AAPL  0.039470  0.027349   \n",
       "...           ...               ...           ...    ...       ...       ...   \n",
       "20903  2025-10-27         -2.020124      0.132638   MSFT  0.015107  0.006880   \n",
       "20904  2025-10-28         -1.909825      0.148105   MSFT  0.019849  0.006466   \n",
       "20905  2025-10-29         -1.905825      0.148699   MSFT -0.000959  0.005909   \n",
       "20906  2025-10-30         -1.632705      0.195399   MSFT -0.029157  0.016145   \n",
       "20907  2025-10-31         -1.698286      0.182996   MSFT -0.015121  0.018852   \n",
       "\n",
       "       return_sharpe_20d  macd_diff    vol_3d  market_stress_1d_lag  ...  \\\n",
       "0               0.000000   0.000000  0.493362              0.000000  ...   \n",
       "1               0.000000  -0.000986  0.493684              0.017709  ...   \n",
       "2               0.000000  -0.001383  0.493849              0.032465  ...   \n",
       "3               0.000000  -0.000721  0.494255              0.012322  ...   \n",
       "4               0.000000   0.001080  0.473882              0.009235  ...   \n",
       "...                  ...        ...       ...                   ...  ...   \n",
       "20903           0.185402   0.001274  0.142235              0.008716  ...   \n",
       "20904           0.237702   0.001929  0.142801              0.010675  ...   \n",
       "20905           0.214903   0.000902  0.143147              0.011097  ...   \n",
       "20906           0.086663  -0.001599  0.164068              0.011743  ...   \n",
       "20907           0.009500  -0.002194  0.175698              0.027665  ...   \n",
       "\n",
       "        vol_60d  vol_entropy   skew_5d  vol_kurt_20d  vol_ratio  ewma_vol_10d  \\\n",
       "0      0.000000     0.000000  0.000000      0.000000   0.999998      0.493362   \n",
       "1      0.000000     0.000000  0.000000      0.000000   0.999998      0.493479   \n",
       "2      0.000000     0.000000  0.628032      0.000000   0.999998      0.493607   \n",
       "3      0.000000     0.000000 -0.049140      0.000000   1.000450      0.493783   \n",
       "4      0.000000     0.000000  0.660010      0.000000   0.983558      0.482711   \n",
       "...         ...          ...       ...           ...        ...           ...   \n",
       "20903  0.167869 -1315.194138  0.848502      1.632760   0.950492      0.147616   \n",
       "20904  0.166809 -1320.893085  0.269403      1.735806   0.959574      0.147705   \n",
       "20905  0.165532 -1339.605424  0.290157      1.902887   0.966849      0.147886   \n",
       "20906  0.164996  -600.297462 -0.895050      7.665364   1.078512      0.156524   \n",
       "20907  0.164258  -589.253296 -0.213075      4.396396   1.131444      0.161337   \n",
       "\n",
       "       vol_stress     rsi_14  vol_skew_20d  abs_return  \n",
       "0        0.017709   0.000000      0.000000    0.018231  \n",
       "1        0.032465   0.000000      0.000000    0.002776  \n",
       "2        0.012322   0.000000      0.000000    0.005398  \n",
       "3        0.009239   0.000000      0.000000    0.018447  \n",
       "4        0.014591   0.000000      0.000000    0.039470  \n",
       "...           ...        ...           ...         ...  \n",
       "20903    0.010147  60.651309     -0.860415    0.015107  \n",
       "20904    0.010649  58.571901     -0.889229    0.019849  \n",
       "20905    0.011354  51.533138     -0.936720    0.000959  \n",
       "20906    0.029837  47.234082      2.032174    0.029157  \n",
       "20907    0.058284  40.989821      1.775281    0.015121  \n",
       "\n",
       "[20908 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df = pd.read_csv(\"../data/processed/volnetx_multi_ticker_data.csv\")\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ VolNetX Training Cell (CPU Test Run on 4-Ticker Set)\n",
    "\n",
    "from volsense_core.models.volnetx import VolNetXConfig, train_volnetx, evaluate_volnetx\n",
    "from volsense_core.models.volnetx import build_volnetx_dataset\n",
    "\n",
    "# Load preprocessed dataset (ensure it has the selected features + realized_vol_log)\n",
    "df = multi_df\n",
    "\n",
    "# --- Feature set: Finalized after analysis\n",
    "# Optimal Feature Set for VolNetX (Input Size = 15)\n",
    "# Final Feature Set for VolNetX\n",
    "# Count: 18 Features (plus 'return' and 'realized_vol' base features = 20 total)\n",
    "\n",
    "EXTRA_FEATURES = [\n",
    "    # --- Core Trends (Autoregressive) ---\n",
    "    \"vol_20d\", \"vol_60d\", \"vol_3d\",  # Short, Medium, Long term memory\n",
    "    \n",
    "    # --- Volatility Dynamics (2nd Order) ---\n",
    "    \"vol_vol\",       # Vol of Vol (Tail risk proxy)\n",
    "    \"vol_entropy\",   # Regime stability\n",
    "    \"vol_chg\",       # Velocity of vol changes\n",
    "    \"vol_ratio\",     # Mean reversion signal\n",
    "    \n",
    "    # --- Price & Momentum ---\n",
    "    \"abs_return\",    # Magnitude of moves\n",
    "    \"macd_diff\",     # Trend shifts\n",
    "    \"rsi_14\",        # Overbought/Oversold conditions\n",
    "    \n",
    "    # --- Macro & Stress Regimes (Sector Drivers) ---\n",
    "    \"macro_VIX\",     # Global fear gauge\n",
    "    \"macro_Oil\",     # Energy sector driver\n",
    "    \"macro_BTC\",     # Risk-on/Liquidity proxy (Tech corr)\n",
    "    \"macro_Rates\",   # Valuation driver (Tech discount rate)\n",
    "    \"market_stress\", # Cross-sectional dispersion\n",
    "    \"vol_stress\",    # Interaction term (Idiosyncratic vs Market)\n",
    "    \n",
    "    # --- Distribution ---\n",
    "    \"skew_scaled_return\" # Asymmetry/Crash risk\n",
    "]\n",
    "\n",
    "# Note: 'return' and 'realized_vol' are usually base features included \n",
    "# automatically by the data loader, but if not, add them to this list.\n",
    "\n",
    "# --- Config + Train\n",
    "cfg = VolNetXConfig(\n",
    "    window=65,\n",
    "    input_size=len(features),\n",
    "    horizons=[1, 5, 10],\n",
    "    device=\"cpu\",\n",
    "    epochs=2,\n",
    "    batch_size=64,\n",
    "    early_stop=True,\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "ticker_to_id, train_loader, val_loader, train_ds, val_ds = build_volnetx_dataset(\n",
    "    df=df,\n",
    "    features=features,\n",
    "    window=cfg.window,\n",
    "    horizons=cfg.horizons,\n",
    "    batch_size=cfg.batch_size,\n",
    "    device=cfg.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a25e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x81 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtrain_volnetx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tickers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticker_to_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:180\u001b[39m, in \u001b[36mtrain_volnetx\u001b[39m\u001b[34m(config, train_loader, val_loader, n_tickers)\u001b[39m\n\u001b[32m    178\u001b[39m x, tidx, y = x.to(config.device), tidx.to(config.device), y.to(config.device)\n\u001b[32m    179\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m loss = \u001b[38;5;28msum\u001b[39m(w * loss_fn(preds[:, i], y[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(config.loss_horizon_weights))\n\u001b[32m    182\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:129\u001b[39m, in \u001b[36mVolNetX.forward\u001b[39m\u001b[34m(self, tidx, x)\u001b[39m\n\u001b[32m    126\u001b[39m     x = torch.cat([x, emb], dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [B, T, F + emb_dim]\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_feature_attention:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, T, F]\u001b[39;00m\n\u001b[32m    131\u001b[39m x, _ = \u001b[38;5;28mself\u001b[39m.encoder(x)  \u001b[38;5;66;03m# [B, T, H]\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_transformer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:50\u001b[39m, in \u001b[36mFeatureAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# x: [B, T, F]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     weights = \u001b[38;5;28mself\u001b[39m.softmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# [B, T, F]\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x * weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1024x81 and 32x32)"
     ]
    }
   ],
   "source": [
    "model = train_volnetx(cfg, train_loader, val_loader, n_tickers=len(ticker_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42161be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. VolNetX Configuration\n",
    "from volsense_core.forecaster_core import VolSenseForecaster\n",
    "import torch\n",
    "\n",
    "# --- 1. Feature Set (18 Extra + 'return' + 'realized_vol') ---\n",
    "EXTRA_FEATURES = [\n",
    "    # --- Core Trends ---\n",
    "    \"vol_20d\", \"vol_60d\", \"vol_3d\",\n",
    "    # --- Volatility Dynamics ---\n",
    "    \"vol_vol\", \"vol_entropy\", \"vol_chg\", \"vol_ratio\",\n",
    "    # --- Price & Momentum ---\n",
    "    \"abs_return\", \"macd_diff\", \"rsi_14\",\n",
    "    # --- Macro & Stress ---\n",
    "    \"macro_VIX\", \"macro_Oil\", \"macro_BTC\", \"macro_Rates\",\n",
    "    \"market_stress\", \"vol_stress\",\n",
    "    # --- Distribution ---\n",
    "    \"skew_scaled_return\"\n",
    "]\n",
    "\n",
    "# --- 2. Hyperparameters ---\n",
    "MODEL_VERSION = \"v701_volnetx\"  # Unique tag for this run\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"window\": 65,                # 3 months context for Transformer\n",
    "    \"horizons\": [1, 5, 10],      # Multi-horizon target\n",
    "    \"loss_horizon_weights\": [0.5, 0.3, 0.2], # Prioritize 1-day accuracy\n",
    "    \"hidden_dim\": 160,           # d_model size\n",
    "    \"num_layers\": 3,             # Depth (LSTM + Transformer blocks)\n",
    "    \"epochs\": 50,                # Max epochs (early stopping will handle overtraining)\n",
    "    \"batch_size\": 128,           # Larger batch for stable gradients\n",
    "    \"lr\": 8e-4,                  # Slightly conservative learning rate\n",
    "    \"dropout\": 0.2,              # Regularization\n",
    "    \"val_start\": \"2023-06-01\",   # Validation cutoff\n",
    "    \"use_transformer\": True,     # Enable VolNetX hybrid mode\n",
    "    \"use_feature_attention\": True, # Enable dynamic feature selection\n",
    "    \"global_ckpt_path\": f\"models/{MODEL_VERSION}\" # Save path relative to repo root\n",
    "}\n",
    "\n",
    "print(f\"‚öôÔ∏è configured VolNetX ({MODEL_VERSION}) on {DEVICE}\")\n",
    "print(f\"   Features: {len(EXTRA_FEATURES)} explicit + base features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1350a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Train VolNetX\n",
    "import time\n",
    "\n",
    "# Initialize Forecaster with \"volnetx\" method\n",
    "forecaster = VolSenseForecaster(\n",
    "    method=\"volnetx\",\n",
    "    device=DEVICE,\n",
    "    extra_features=EXTRA_FEATURES,\n",
    "    **TRAIN_CONFIG\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting Training Run...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Run Fit (Handles Dataset Build -> Train -> Save internally)\n",
    "forecaster.fit(df)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n‚úÖ Training Complete in {(end_time - start_time)/60:.1f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba313e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading subset from ../data/processed/master_lstm_dataset_v2.csv...\n",
      "   Loaded 10000 rows for testing.\n",
      "\n",
      "üöÄ Starting Test Run...\n",
      "üß† Training VolNetX Hybrid Model...\n",
      "   ‚Ü≥ Building VolNetX dataset (causal mode)...\n",
      "   ‚öñÔ∏è Fitting new global scaler (Train split only)...\n",
      "   ‚Ü≥ Starting training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Train Loss: 0.1195 | Val Loss: 0.1219\n",
      "Epoch 2/2 - Train Loss: 0.0568 | Val Loss: 0.0913\n",
      "\n",
      "‚úÖ Test Run Complete! Training loop is functional.\n"
     ]
    }
   ],
   "source": [
    "# @title üß™ Quick Training Test (2 Epochs)\n",
    "import pandas as pd\n",
    "import torch\n",
    "from volsense_core.forecaster_core import VolSenseForecaster\n",
    "\n",
    "# 1. Load Small Data Subset\n",
    "DATA_PATH = \"../data/processed/master_lstm_dataset_v2.csv\"\n",
    "print(f\"üìÇ Loading subset from {DATA_PATH}...\")\n",
    "\n",
    "# Read just 10k rows to be fast\n",
    "df_test = pd.read_csv(DATA_PATH, parse_dates=[\"date\"]).iloc[-10000:].copy() \n",
    "print(f\"   Loaded {len(df_test)} rows for testing.\")\n",
    "\n",
    "# 2. Define Minimal Config\n",
    "TEST_CONFIG = {\n",
    "    \"window\": 30,               # Short window for speed\n",
    "    \"horizons\": [1, 5],         # Reduced horizons\n",
    "    \"hidden_dim\": 32,           # Tiny model\n",
    "    \"num_layers\": 1,\n",
    "    \"epochs\": 2,                # Just 2 epochs\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-3,\n",
    "    \"val_mode\": \"causal\",\n",
    "    \"val_start\": \"2024-01-01\",  # Ensure this date exists in your subset!\n",
    "    \"loss_horizon_weights\": [0.7, 0.3],\n",
    "    \"use_transformer\": True,\n",
    "    \"use_feature_attention\": True\n",
    "}\n",
    "\n",
    "# 3. Run Training\n",
    "print(\"\\nüöÄ Starting Test Run...\")\n",
    "try:\n",
    "    forecaster = VolSenseForecaster(\n",
    "        method=\"volnetx\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        extra_features=[\"vol_20d\", \"vol_vol\"], # Minimal features\n",
    "        **TEST_CONFIG\n",
    "    )\n",
    "    \n",
    "    forecaster.fit(df_test)\n",
    "    print(\"\\n‚úÖ Test Run Complete! Training loop is functional.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Test Failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
