{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68767246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Environment Setup & Branch Checkout\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount Drive to persist models/data\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Clone & Switch Branch\n",
    "repo_path = \"/content/VolSense\"\n",
    "if not os.path.exists(repo_path):\n",
    "    !git clone https://github.com/rahulmkarthik/VolSense.git $repo_path\n",
    "    %cd $repo_path\n",
    "    !git fetch origin feature/volnetx\n",
    "    !git checkout feature/volnetx\n",
    "    print(\"‚úÖ Checked out branch: feature/volnetx\")\n",
    "else:\n",
    "    %cd $repo_path\n",
    "    !git pull origin feature/volnetx\n",
    "    print(\"‚úÖ Repo updated.\")\n",
    "\n",
    "# 3. Install Dependencies (Editable mode to ensure local changes apply)\n",
    "!pip install -r requirements.txt --quiet\n",
    "!pip install -e . --quiet\n",
    "\n",
    "# 4. Verify Structure\n",
    "print(\"\\nüìÇ Current Working Directory:\", os.getcwd())\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "    print(\"   created 'models/' directory for artifacts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üåç Fetching market data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.50ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Load Engineered Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# ‚ö†Ô∏è UPDATE THIS PATH to where you uploaded your file\n",
    "DATASET_PATH = \"/content/drive/MyDrive/VolNetX_training_data/unzipped/master_lstm_dataset_v2.csv\"\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"‚ö†Ô∏è File not found at {DATASET_PATH}. Please upload it.\")\n",
    "else:\n",
    "    print(f\"üöÄ Loading dataset from {DATASET_PATH}...\")\n",
    "    df = pd.read_csv(DATASET_PATH, parse_dates=[\"date\"])\n",
    "\n",
    "    # Quick sanity check\n",
    "    print(f\"   Rows: {len(df):,}\")\n",
    "    print(f\"   Tickers: {df['ticker'].nunique()}\")\n",
    "\n",
    "    # Verify new features exist\n",
    "    expected_cols = [\"macro_Oil\", \"vol_entropy\", \"skew_scaled_return\"]\n",
    "    missing = [c for c in expected_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"‚ùå WARNING: Missing features: {missing}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All key engineered features found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebc568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>realized_vol_log</th>\n",
       "      <th>realized_vol</th>\n",
       "      <th>ticker</th>\n",
       "      <th>return</th>\n",
       "      <th>vol_vol</th>\n",
       "      <th>return_sharpe_20d</th>\n",
       "      <th>macd_diff</th>\n",
       "      <th>vol_3d</th>\n",
       "      <th>market_stress_1d_lag</th>\n",
       "      <th>...</th>\n",
       "      <th>vol_60d</th>\n",
       "      <th>vol_entropy</th>\n",
       "      <th>skew_5d</th>\n",
       "      <th>vol_kurt_20d</th>\n",
       "      <th>vol_ratio</th>\n",
       "      <th>ewma_vol_10d</th>\n",
       "      <th>vol_stress</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>vol_skew_20d</th>\n",
       "      <th>abs_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-25</td>\n",
       "      <td>-0.706510</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-26</td>\n",
       "      <td>-0.705208</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.493684</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493479</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>-0.704852</td>\n",
       "      <td>0.494181</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.493607</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-28</td>\n",
       "      <td>-0.704045</td>\n",
       "      <td>0.494579</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>0.494255</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.049140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000450</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>-0.837282</td>\n",
       "      <td>0.432884</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.473882</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983558</td>\n",
       "      <td>0.482711</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20903</th>\n",
       "      <td>2025-10-27</td>\n",
       "      <td>-2.020124</td>\n",
       "      <td>0.132638</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.185402</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.142235</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167869</td>\n",
       "      <td>-1315.194138</td>\n",
       "      <td>0.848502</td>\n",
       "      <td>1.632760</td>\n",
       "      <td>0.950492</td>\n",
       "      <td>0.147616</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>60.651309</td>\n",
       "      <td>-0.860415</td>\n",
       "      <td>0.015107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20904</th>\n",
       "      <td>2025-10-28</td>\n",
       "      <td>-1.909825</td>\n",
       "      <td>0.148105</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.237702</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.142801</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166809</td>\n",
       "      <td>-1320.893085</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>1.735806</td>\n",
       "      <td>0.959574</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>58.571901</td>\n",
       "      <td>-0.889229</td>\n",
       "      <td>0.019849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20905</th>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>-1.905825</td>\n",
       "      <td>0.148699</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.214903</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.143147</td>\n",
       "      <td>0.011097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>-1339.605424</td>\n",
       "      <td>0.290157</td>\n",
       "      <td>1.902887</td>\n",
       "      <td>0.966849</td>\n",
       "      <td>0.147886</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>51.533138</td>\n",
       "      <td>-0.936720</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20906</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>-1.632705</td>\n",
       "      <td>0.195399</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.029157</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>0.164068</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164996</td>\n",
       "      <td>-600.297462</td>\n",
       "      <td>-0.895050</td>\n",
       "      <td>7.665364</td>\n",
       "      <td>1.078512</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>47.234082</td>\n",
       "      <td>2.032174</td>\n",
       "      <td>0.029157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20907</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>-1.698286</td>\n",
       "      <td>0.182996</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.015121</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>0.175698</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>-589.253296</td>\n",
       "      <td>-0.213075</td>\n",
       "      <td>4.396396</td>\n",
       "      <td>1.131444</td>\n",
       "      <td>0.161337</td>\n",
       "      <td>0.058284</td>\n",
       "      <td>40.989821</td>\n",
       "      <td>1.775281</td>\n",
       "      <td>0.015121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20908 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  realized_vol_log  realized_vol ticker    return   vol_vol  \\\n",
       "0      2005-01-25         -0.706510      0.493362   AAPL  0.018231  0.000000   \n",
       "1      2005-01-26         -0.705208      0.494005   AAPL  0.002776  0.000455   \n",
       "2      2005-01-27         -0.704852      0.494181   AAPL  0.005398  0.000431   \n",
       "3      2005-01-28         -0.704045      0.494579   AAPL  0.018447  0.000507   \n",
       "4      2005-01-31         -0.837282      0.432884   AAPL  0.039470  0.027349   \n",
       "...           ...               ...           ...    ...       ...       ...   \n",
       "20903  2025-10-27         -2.020124      0.132638   MSFT  0.015107  0.006880   \n",
       "20904  2025-10-28         -1.909825      0.148105   MSFT  0.019849  0.006466   \n",
       "20905  2025-10-29         -1.905825      0.148699   MSFT -0.000959  0.005909   \n",
       "20906  2025-10-30         -1.632705      0.195399   MSFT -0.029157  0.016145   \n",
       "20907  2025-10-31         -1.698286      0.182996   MSFT -0.015121  0.018852   \n",
       "\n",
       "       return_sharpe_20d  macd_diff    vol_3d  market_stress_1d_lag  ...  \\\n",
       "0               0.000000   0.000000  0.493362              0.000000  ...   \n",
       "1               0.000000  -0.000986  0.493684              0.017709  ...   \n",
       "2               0.000000  -0.001383  0.493849              0.032465  ...   \n",
       "3               0.000000  -0.000721  0.494255              0.012322  ...   \n",
       "4               0.000000   0.001080  0.473882              0.009235  ...   \n",
       "...                  ...        ...       ...                   ...  ...   \n",
       "20903           0.185402   0.001274  0.142235              0.008716  ...   \n",
       "20904           0.237702   0.001929  0.142801              0.010675  ...   \n",
       "20905           0.214903   0.000902  0.143147              0.011097  ...   \n",
       "20906           0.086663  -0.001599  0.164068              0.011743  ...   \n",
       "20907           0.009500  -0.002194  0.175698              0.027665  ...   \n",
       "\n",
       "        vol_60d  vol_entropy   skew_5d  vol_kurt_20d  vol_ratio  ewma_vol_10d  \\\n",
       "0      0.000000     0.000000  0.000000      0.000000   0.999998      0.493362   \n",
       "1      0.000000     0.000000  0.000000      0.000000   0.999998      0.493479   \n",
       "2      0.000000     0.000000  0.628032      0.000000   0.999998      0.493607   \n",
       "3      0.000000     0.000000 -0.049140      0.000000   1.000450      0.493783   \n",
       "4      0.000000     0.000000  0.660010      0.000000   0.983558      0.482711   \n",
       "...         ...          ...       ...           ...        ...           ...   \n",
       "20903  0.167869 -1315.194138  0.848502      1.632760   0.950492      0.147616   \n",
       "20904  0.166809 -1320.893085  0.269403      1.735806   0.959574      0.147705   \n",
       "20905  0.165532 -1339.605424  0.290157      1.902887   0.966849      0.147886   \n",
       "20906  0.164996  -600.297462 -0.895050      7.665364   1.078512      0.156524   \n",
       "20907  0.164258  -589.253296 -0.213075      4.396396   1.131444      0.161337   \n",
       "\n",
       "       vol_stress     rsi_14  vol_skew_20d  abs_return  \n",
       "0        0.017709   0.000000      0.000000    0.018231  \n",
       "1        0.032465   0.000000      0.000000    0.002776  \n",
       "2        0.012322   0.000000      0.000000    0.005398  \n",
       "3        0.009239   0.000000      0.000000    0.018447  \n",
       "4        0.014591   0.000000      0.000000    0.039470  \n",
       "...           ...        ...           ...         ...  \n",
       "20903    0.010147  60.651309     -0.860415    0.015107  \n",
       "20904    0.010649  58.571901     -0.889229    0.019849  \n",
       "20905    0.011354  51.533138     -0.936720    0.000959  \n",
       "20906    0.029837  47.234082      2.032174    0.029157  \n",
       "20907    0.058284  40.989821      1.775281    0.015121  \n",
       "\n",
       "[20908 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title 3. VolNetX Configuration\n",
    "from volsense_core.forecaster_core import VolSenseForecaster\n",
    "import torch\n",
    "\n",
    "# --- 1. Feature Set (18 Extra + 'return' + 'realized_vol') ---\n",
    "EXTRA_FEATURES = [\n",
    "    # --- Core Trends ---\n",
    "    \"vol_20d\", \"vol_60d\", \"vol_3d\", \"vol_10d\",\n",
    "    # --- Volatility Dynamics ---\n",
    "    \"vol_vol\", \"vol_entropy\", \"vol_chg\", \"vol_ratio\",\n",
    "    # --- Price & Momentum ---\n",
    "    \"abs_return\", \"macd_diff\", \"rsi_14\",\n",
    "    # --- Macro & Stress ---\n",
    "    \"macro_VIX\", \"macro_Oil\",\n",
    "    \"market_stress\", \"vol_stress\",\n",
    "    # --- Distribution ---\n",
    "    \"skew_scaled_return\"\n",
    "]\n",
    "\n",
    "# --- 2. Hyperparameters ---\n",
    "MODEL_VERSION = \"v701_volnetx_v8\"  # Unique tag for this run\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"window\": 65,                # 3 months context for Transformer\n",
    "    \"horizons\": [1, 5, 10],      # Multi-horizon target\n",
    "    \"loss_horizon_weights\": [0.5, 0.3, 0.2], # Prioritize 1-day accuracy\n",
    "    \"hidden_dim\": 128,           # d_model size\n",
    "    \"num_layers\": 3,             # Depth (LSTM + Transformer blocks)\n",
    "    \"epochs\": 50,                # Max epochs (early stopping will handle overtraining)\n",
    "    \"batch_size\": 128,           # Larger batch for stable gradients\n",
    "    \"lr\": 6e-4,                  # Slightly conservative learning rate\n",
    "    \"cosine_schedule\" : True,\n",
    "    \"dropout\": 0.2,              # Regularization\n",
    "    \"grad_clip\" : 1.0,\n",
    "    \"weight_decay\" : 2e-5,\n",
    "    \"val_start\": \"2023-06-01\",   # Validation cutoff\n",
    "    \"use_transformer\": True,     # Enable VolNetX hybrid mode\n",
    "    \"use_feature_attention\": True, # Enable dynamic feature selection\n",
    "    \"global_ckpt_path\": f\"models/{MODEL_VERSION}\", # Save path relative to repo root\n",
    "    \"patience\" : 13\n",
    "}\n",
    "\n",
    "print(f\"‚öôÔ∏è configured VolNetX ({MODEL_VERSION}) on {DEVICE}\")\n",
    "print(f\"   Features: {len(EXTRA_FEATURES)} explicit + base features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Train VolNetX\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# Initialize Forecaster with \"volnetx\" method\n",
    "forecaster = VolSenseForecaster(\n",
    "    method=\"volnetx\",\n",
    "    device=DEVICE,\n",
    "    extra_features=EXTRA_FEATURES,\n",
    "    **TRAIN_CONFIG\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting Training Run...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Run Fit (Handles Dataset Build -> Train -> Save internally)\n",
    "forecaster.fit(df)\n",
    "\n",
    "# üõ°Ô∏è Auto-Backup to Drive\n",
    "drive_save_dir = \"/content/drive/MyDrive/Colab_files/VolSense/models\"\n",
    "os.makedirs(drive_save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Backing up artifacts to Drive: {drive_save_dir}...\")\n",
    "# Copy all files starting with the model version\n",
    "for f in os.listdir(\"models\"):\n",
    "    if f.startswith(MODEL_VERSION):\n",
    "        shutil.copy2(os.path.join(\"models\", f), drive_save_dir)\n",
    "        print(f\"   ‚úÖ Copied {f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n‚úÖ Training Complete in {(end_time - start_time)/60:.1f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a25e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x81 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtrain_volnetx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tickers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticker_to_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:180\u001b[39m, in \u001b[36mtrain_volnetx\u001b[39m\u001b[34m(config, train_loader, val_loader, n_tickers)\u001b[39m\n\u001b[32m    178\u001b[39m x, tidx, y = x.to(config.device), tidx.to(config.device), y.to(config.device)\n\u001b[32m    179\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m loss = \u001b[38;5;28msum\u001b[39m(w * loss_fn(preds[:, i], y[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(config.loss_horizon_weights))\n\u001b[32m    182\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:129\u001b[39m, in \u001b[36mVolNetX.forward\u001b[39m\u001b[34m(self, tidx, x)\u001b[39m\n\u001b[32m    126\u001b[39m     x = torch.cat([x, emb], dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [B, T, F + emb_dim]\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_feature_attention:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, T, F]\u001b[39;00m\n\u001b[32m    131\u001b[39m x, _ = \u001b[38;5;28mself\u001b[39m.encoder(x)  \u001b[38;5;66;03m# [B, T, H]\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_transformer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documents\\GitHub\\VolSense\\volsense_core\\models\\volnetx.py:50\u001b[39m, in \u001b[36mFeatureAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# x: [B, T, F]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     weights = \u001b[38;5;28mself\u001b[39m.softmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# [B, T, F]\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x * weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rahul\\OneDrive\\Documents\\GitHub\\VolSense\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1024x81 and 32x32)"
     ]
    }
   ],
   "source": [
    "# @title 6. Evaluate VolNetX Performance\n",
    "from volsense_core.evaluation.evaluation import ModelEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Run Predictions on Test Set (Forecasts aligned with Realized Vol)\n",
    "#    The 'predict' method automatically handles rolling windows and inverse log-transform\n",
    "print(\"üîÆ Generating rolling forecasts on validation set...\")\n",
    "preds_df = forecaster.predict(df, mode=\"eval\")\n",
    "\n",
    "# Filter for validation period only to be fair\n",
    "val_start_date = pd.to_datetime(TRAIN_CONFIG[\"val_start\"])\n",
    "preds_df = preds_df[preds_df['asof_date'] >= val_start_date].copy()\n",
    "\n",
    "print(f\"‚úÖ Generated {len(preds_df):,} predictions from {val_start_date.date()}\")\n",
    "\n",
    "# 2. Initialize Evaluator\n",
    "evaluator = ModelEvaluator(preds_df, model_name=MODEL_VERSION)\n",
    "\n",
    "# 3. Compute & Show Metrics\n",
    "metrics_df = evaluator.compute_metrics()\n",
    "summary_df = evaluator.summarize()\n",
    "\n",
    "# 4. Visualization: True vs Pred (Linear Scale)\n",
    "#    We look for tight clustering around the diagonal (red line)\n",
    "def plot_performance(df, horizon=1):\n",
    "    subset = df[df['horizon'] == horizon]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Scatter Plot\n",
    "    sns.scatterplot(data=subset, x='realized_vol', y='forecast_vol', alpha=0.1, ax=ax[0])\n",
    "    max_val = max(subset['realized_vol'].max(), subset['forecast_vol'].max())\n",
    "    ax[0].plot([0, max_val], [0, max_val], 'r--', label='Perfect Prediction')\n",
    "    ax[0].set_title(f\"Horizon {horizon}d: Forecast vs Realized\")\n",
    "    ax[0].set_xlabel(\"True Volatility\")\n",
    "    ax[0].set_ylabel(\"Predicted Volatility\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Residual Distribution\n",
    "    residuals = subset['forecast_vol'] - subset['realized_vol']\n",
    "    sns.histplot(residuals, bins=50, kde=True, ax=ax[1])\n",
    "    ax[1].set_title(f\"Horizon {horizon}d: Residuals (Error)\")\n",
    "    ax[1].set_xlabel(\"Error (Pred - True)\")\n",
    "    ax[1].axvline(0, color='r', linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüìä Visualizing 1-Day Horizon Performance:\")\n",
    "plot_performance(preds_df, horizon=1)\n",
    "\n",
    "if 5 in TRAIN_CONFIG[\"horizons\"]:\n",
    "    print(\"\\nüìä Visualizing 5-Day Horizon Performance:\")\n",
    "    plot_performance(preds_df, horizon=5)\n",
    "\n",
    "if 10 in TRAIN_CONFIG[\"horizons\"]:\n",
    "    print(\"\\nüìä Visualizing 10-Day Horizon Performance:\")\n",
    "    plot_performance(preds_df, horizon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75016fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"/content/drive/MyDrive/Colab_files/VolSense/models/{MODEL_VERSION}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42161be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Compare against v507 (Global LSTM)\n",
    "from volsense_core.utils.scalers import TorchStandardScaler\n",
    "from volsense_inference.model_loader import load_model\n",
    "import types\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Load v507 Artifacts\n",
    "MODEL_V507 = \"v507\"  # Ensure this matches the folder name in 'models/'\n",
    "print(f\"ü§ñ Loading Baseline Model: {MODEL_V507}...\")\n",
    "\n",
    "try:\n",
    "    # Load raw artifacts\n",
    "    model_507, meta_507, _, t2i_507, feats_507 = load_model(MODEL_V507, \"models\", device=DEVICE)\n",
    "\n",
    "    # 2. JIT Scaler Reconstruction (Critical for v507)\n",
    "    #    v507 expects specific features. We must create scalers for IT, not VolNetX.\n",
    "    print(f\"   üõ†Ô∏è Reconstructing scalers for {len(t2i_507)} tickers...\")\n",
    "    scalers_507 = {}\n",
    "\n",
    "    # Use the full 'df' to approximate scaling stats for inference\n",
    "    # (Strictly, this should be training-only data, but for a quick check this works)\n",
    "    df_grouped = df.groupby(\"ticker\")\n",
    "\n",
    "    for t in t2i_507:\n",
    "        sc = TorchStandardScaler()\n",
    "        if t in df_grouped.groups:\n",
    "            t_df = df_grouped.get_group(t)\n",
    "            # Only use features v507 was trained on\n",
    "            valid_feats = [f for f in feats_507 if f in t_df.columns]\n",
    "\n",
    "            if valid_feats:\n",
    "                data_vals = t_df[valid_feats].values.astype(float)\n",
    "                data_vals = np.nan_to_num(data_vals)\n",
    "                sc.fit(torch.tensor(data_vals, dtype=torch.float32))\n",
    "                sc.feature_names_in_ = valid_feats # CRITICAL for predict_next_day\n",
    "            else:\n",
    "                # Feature mismatch fallback\n",
    "                dim = len(feats_507)\n",
    "                sc.mean_ = torch.zeros(dim)\n",
    "                sc.scale_ = torch.ones(dim)\n",
    "                sc.feature_names_in_ = feats_507\n",
    "        else:\n",
    "            # Ticker unknown to current dataset\n",
    "            dim = len(feats_507)\n",
    "            sc.mean_ = torch.zeros(dim)\n",
    "            sc.scale_ = torch.ones(dim)\n",
    "            sc.feature_names_in_ = feats_507\n",
    "\n",
    "        scalers_507[t] = sc\n",
    "\n",
    "    # 3. Hydrate Forecaster Wrapper\n",
    "    vf_507 = VolSenseForecaster(method=\"global_lstm\", device=DEVICE)\n",
    "    vf_507.model = model_507\n",
    "    vf_507.global_ticker_to_id = t2i_507\n",
    "    vf_507.global_scalers = scalers_507\n",
    "    vf_507.global_window = meta_507.get(\"window\", 40)\n",
    "\n",
    "    # Mock config\n",
    "    vf_507.cfg = types.SimpleNamespace()\n",
    "    vf_507.cfg.horizons = meta_507.get(\"horizons\", [1, 5, 10])\n",
    "\n",
    "    # 4. Predict\n",
    "    print(f\"üîÆ Generating v507 forecasts on validation set...\")\n",
    "    preds_507 = vf_507.predict(df, mode=\"eval\")\n",
    "\n",
    "    # Filter to same validation window as VolNetX for fair comparison\n",
    "    preds_507 = preds_507[preds_507['asof_date'] >= val_start_date].copy()\n",
    "\n",
    "    # 5. Evaluate\n",
    "    eval_507 = ModelEvaluator(preds_507, model_name=f\"Baseline_{MODEL_V507}\")\n",
    "    summary_507 = eval_507.summarize()\n",
    "\n",
    "    # 6. Head-to-Head Comparison Table\n",
    "    print(\"\\nüèÜ Head-to-Head: VolNetX vs v507 (1-Day Horizon)\")\n",
    "\n",
    "    # Extract 1d rows\n",
    "    res_volnet = summary_df[summary_df['horizon'] == 1].copy()\n",
    "    res_volnet['Model'] = \"VolNetX\"\n",
    "\n",
    "    res_507 = summary_507[summary_507['horizon'] == 1].copy()\n",
    "    res_507['Model'] = \"v507 (LSTM)\"\n",
    "\n",
    "    comp_table = pd.concat([res_volnet, res_507], ignore_index=True)\n",
    "    cols = ['Model', 'RMSE', 'MAE', 'R2', 'Corr', 'DW']\n",
    "    display(comp_table[cols].style.background_gradient(cmap=\"Greens\", subset=['R2', 'Corr']).background_gradient(cmap=\"Reds_r\", subset=['RMSE', 'MAE']))\n",
    "\n",
    "    # 7. Visual Comparison (Scatter)\n",
    "    print(\"\\nüìä Visual Comparison (1-Day):\")\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "    # VolNetX\n",
    "    vx_data = preds_df[preds_df['horizon'] == 1]\n",
    "    sns.scatterplot(data=vx_data, x='realized_vol', y='forecast_vol', alpha=0.15, ax=ax[0], color='blue')\n",
    "    ax[0].plot([0, 0.04], [0, 0.04], 'k--', lw=1)\n",
    "    ax[0].set_title(f\"VolNetX (R2: {res_volnet['R2'].iloc[0]:.3f})\")\n",
    "\n",
    "    # v507\n",
    "    v5_data = preds_507[preds_507['horizon'] == 1]\n",
    "    sns.scatterplot(data=v5_data, x='realized_vol', y='forecast_vol', alpha=0.15, ax=ax[1], color='red')\n",
    "    ax[1].plot([0, 0.04], [0, 0.04], 'k--', lw=1)\n",
    "    ax[1].set_title(f\"v507 (R2: {res_507['R2'].iloc[0]:.3f})\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Comparison failed: {e}\")\n",
    "    print(\"Tip: Ensure 'v507' folder exists in models/ and contains .pth + .meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1350a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Multi-Horizon Analysis (5d & 10d)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Define horizons to analyze\n",
    "analyze_horizons = [5, 10]\n",
    "\n",
    "# Ensure we have the summary DFs (computed in previous cells)\n",
    "# summary_df = evaluator.summarize()  <-- VolNetX\n",
    "# summary_507 = eval_507.summarize()  <-- v507 Baseline\n",
    "\n",
    "for h in analyze_horizons:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìÖ  {h}-DAY HORIZON COMPARISON\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Filter & Merge Metrics\n",
    "    try:\n",
    "        # Extract rows for specific horizon\n",
    "        row_volnet = summary_df[summary_df['horizon'] == h].copy()\n",
    "        row_volnet['Model'] = \"VolNetX\"\n",
    "\n",
    "        row_507 = summary_507[summary_507['horizon'] == h].copy()\n",
    "        row_507['Model'] = \"v507 (LSTM)\"\n",
    "\n",
    "        # Combine\n",
    "        comp_table = pd.concat([row_volnet, row_507], ignore_index=True)\n",
    "\n",
    "        # Display Styled Table\n",
    "        cols = ['Model', 'RMSE', 'MAE', 'R2', 'Corr', 'DW']\n",
    "        display(comp_table[cols].style.background_gradient(cmap=\"Greens\", subset=['R2', 'Corr'])\n",
    "                                      .background_gradient(cmap=\"Reds_r\", subset=['RMSE', 'MAE']))\n",
    "\n",
    "        # 2. Visual Comparison\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "        # VolNetX Plot\n",
    "        vx_data = preds_df[preds_df['horizon'] == h]\n",
    "        sns.scatterplot(data=vx_data, x='realized_vol', y='forecast_vol',\n",
    "                        alpha=0.2, ax=ax[0], color='blue')\n",
    "\n",
    "        # Reference Line (Diagonal)\n",
    "        max_val = max(vx_data['realized_vol'].max(), 0.05) # Cap for visibility\n",
    "        ax[0].plot([0, max_val], [0, max_val], 'k--', lw=1.5)\n",
    "        r2_val = row_volnet['R2'].iloc[0] if not row_volnet.empty else 0.0\n",
    "        ax[0].set_title(f\"VolNetX ({h}d) | R¬≤: {r2_val:.3f}\")\n",
    "        ax[0].set_xlabel(\"Realized Vol\")\n",
    "        ax[0].set_ylabel(\"Forecast Vol\")\n",
    "        ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # v507 Plot\n",
    "        v5_data = preds_507[preds_507['horizon'] == h]\n",
    "        sns.scatterplot(data=v5_data, x='realized_vol', y='forecast_vol',\n",
    "                        alpha=0.2, ax=ax[1], color='red')\n",
    "\n",
    "        ax[1].plot([0, max_val], [0, max_val], 'k--', lw=1.5)\n",
    "        r2_507 = row_507['R2'].iloc[0] if not row_507.empty else 0.0\n",
    "        ax[1].set_title(f\"v507 ({h}d) | R¬≤: {r2_507:.3f}\")\n",
    "        ax[1].set_xlabel(\"Realized Vol\")\n",
    "        ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"‚ö†Ô∏è Horizon {h} not found in results. (Did you configure horizons=[1,5,10]?)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating {h}d comparison: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
